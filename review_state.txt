Review 1:
Overall evaluation:	0: (borderline paper)
Reviewer's confidence:	4: (high)
Review:	Strong points:

Generally this is a well-structured paper on activity detection. It provides details on how to implement an embedded system for human and robot activity detection. In particular, this paper demonstrates that highly accurate fall event detection can be achieved with the proposed machine learning algorithm. The contributions of this paper are two folds: 1) a unified and general approach for learning and predicting activities of humans and robots; 2) and software tools that facilitate data collection and processing. 

Weak points:

There exists quite a few typos/errors throughout this paper.
1) These events may causing -> These events may cause
2) we develop a generalize approach -> we develop a generalized approach
3) a modular functionalities -> modular functionalities
4) a wide rage -> a wide range
5) consists for -> consist of
6) the reset -> the rest
There are many more typos/errors than the above-mentioned ones. 

>>> Correct the typos

This paper evaluates their approach using a self-collected dataset -- it would be desirable if the authors can make the dataset publicly available. Indeed, this paper contributes a general approach for fall event detection. However, one major weakness of this paper is that it does not validate the use of accelerometer and gyroscope readings for fall event detection. 

>>> Validation of acc and gyro. I believe this is to interpret the data; we also need a better feature extractor.

The paper compares SVM and LLR in terms of its classification performance. The author should provide motivations of designing this comparison experiment. Anyway, it is no surprise that SVM outperforms LLR in terms of classification accuracy. 

In summary, this paper describes their contributions to the research community on human and robot avtivity detection, but it is less encouraged for publication due to insufficient novelty.

>>> Novelty?



+++++++++++++++++++++++++++

Review: 3
Overall evaluation:	0: (borderline paper)
Reviewer's confidence:	2: (low)
Review:	This paper describes a set of methods and tools to identify and predict when humans and humanoid robots will perform certain activities (such as falling). I felt the area address is very relevant to FLAIRS and has obvious real-world application. Overall I found the problem an interesting one and the method proposed a good first step. However I am not sure the approach and results reached warrant conference publication at this time and might be more appropriate for a workshop. 

There were quite a few language errors making the paper difficult to follow at times. Ignoring that, the overall problem description was straightforward and the authors did a fair job of describing related work. The overall approach seemed sensible but not revolutionary. In Figure 1, it would have been useful to identify the sensors by type (e.g., gyro/accelerometer) vs. giving the module number, which is meaningless to someone who hasn't used those sensors before.

I was glad to see experimental results reported. It would have been good to stipulate the exact number of samples collected and used. The authors mention they used 80% for training and 20% for testing, but do no provide the total number of samples available. In several sections it's mentioned that techniques that had somewhat lower performance than the top technique were preferable due to memory and computation constraints. I easily believe this but it would be good to report on the memory and computational requirements for each technique and to report on the memory and computation limitations of the used or future target embedded devices.

I would also encourage the authors to expand their description of future work. One sentence is the Conclusion is not enough in my opinion. At least add a paragraph. I'm sure there are lots of good directions for this work to go.

>>> Sensors by Type
>>> Experiments



++++++++++++++++++++++++++++++++++++


Overall evaluation:	-1: (weak reject)
Reviewer's confidence:	3: (medium)
Review:	The paper presents methods and software tools to detect, analyze and predict falls for both humans and humanoid robots while using a wearable device. The authors provide a description of the proposed framework in which some specific Texas Instruments components are used and ad-hoc software tools were developed. Two well known learning algorithms (LLR and SVM) are used to analyze data generated by a human and a NAO robot in some specific scenarios. Then, a Kalman filter process is deployed to detect (and thus predict) possible falls while monitoring activities.

The problem addressed in the paper is relevant as well as the methods and tools proposed sound interesting to me. 
Nevertheless, in my opinion, the work presents several issues affecting its overall quality:

- even though some related works are described, the paper does not present a comparison with the methods and tools presented in the paper. So, it is difficult for me to evaluate the actual benefits in using the proposed framework. The experimental results are discussed comparing the use of different learning algorithms but a more thorough comparison should be performed in order to better support the effectiveness of the overall framework.

- Learning algorithms and Kalman filtering approach are well-known and part of the state of the art. So, the general approach seems to be not so original.

- Somehow related to the above points, the paper does not provide too much details about the devices, the architecture and the software framework. So, it is hard to evaluate the relevance/novelty of the approach and it is not clear how much the methods and tools can be ported and/or reproduced with/on different devices or robots. 

- Usually, humanoid robots come with a quite rich set of internal sensors to monitor several parameters and the external environment. And in particular, as far as I know, NAO robots are endowed with a fall detection feature. So, it is not clear to me why an additional external sensor is required in order to detect falls of robots. And why are their internal sensors not enough to perform the same data gathering/analysis?

- Figures 2 and 3 provide the reader with a lot of (graphical) information but a very brief discussion is reported in the paper. So, they seem to fail in providing straightforward evidences as a support for paper conclusions.

- The paper suffers a bad English quality. A proofreading is highly recommended.

For the above reasons, my feeling is that in its current shape the paper does not provide a clear and crisp contribution that can be easily reproduced and/or ported in other platforms/contexts. A comparison of different approaches in the same scenarios seems to be necessary to support paper conclusions. Finally, more details about the devices, algorithms and processes constituting the framework would enhance the quality of the contribution. 

In the following, authors may find a list of minor issues:

Introduction
- references on the use of humanoid robots in rescue scenarios should be reported.

- "...set of learning algorithms are suitable for both groups." When applied to what?

- generalize -> either general or generalized

- "The software tools provide a modular functionalities..." -> functionality

Related Works
- collusion -> collision

- do fall avoidance -> perform fall avoidance

- double check names for references to i) Baek et al 2013 ii) Bai, Wu and Yu 2013 iii) Leone, Rescio and Siciliano 2013.

- prosed -> proposed

- "The microcontrollers and embedded devices provide a flexible platform to build may real world applications." Remove "may"

Our approach and contributions
- check English

Framework
- though -> through

- Our framework consists for four parts -> of four parts

- the text at the beginning of pag 3 is referring to fig 1 but it is not clearly stated.

Experimental setup and empirical evaluations
- architecture and components are not clearly described

Activity annotation
- data processing description seems to be missing (maybe I'm missing something)

Learning algorithms
- reset -> rest

- the assumptions about latency to check falls can be applied in different contexts or with different robots?
Are the assumptions general? How much are these assumptions affecting the effectiveness of the methods?

Experiments with a human
- even though the performance with SVR are better than the ones with SVR "due to memory and computational restrictions on the embedded devices" LLR is considered as best choice. Is this a trade-off between performance and safety? In many cases, having safe system is more crucial than having "fast" system. A more deep discussion on this crucial point is required.

Experiments with NAO robot
- data collection seems to be different with respect to the case with human. Is this difference affecting in some way the overall process? 

- "we repeat the about described..." remove about

Results
- check English

Kalman Filtering
- "the the" -> the

- "and the filtered values of the raw and the pitch values for marching" -> raw should be Roll


Conclusion and Future Work
- "we have used machine two machine learning..." -> remove machine

>>> English

>>> Why: evaluation
		- why is it novelty 
Rotation is missing:
	- extensive experiments for NAO

- How does Robot and Human affects the fall.

Journal and define our own protocol: 
	- Clear what the innovative part: we can do this in the abstract
	- Conclusion: papers novelty
			- time abstraction 
			- synchronization
			- time petrinate ...
 				- transition; 
					- HMM
					- time warping ...

Introduction and review: Saminda

-- Group this papers based on the sensor types they used. 

-- Add a papragraph and list a type of sensor others used MEMS; detection of faults. 

-- Papers; list the type of faults for humans and robots; group by accordings
	-- Count of the number. 

-- Smart phone section; and the embedded section:

-- Razor paper neeeds to be sensor types.

-- Mapping from module names to human readable names: Saminda, send the names to Ubbo : Done

-- Human activity complete section : Faisal

-- Data collection must be clearly mention before the activity; and data preprocessing and learning algorithms: Faisal 




